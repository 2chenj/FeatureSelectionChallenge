{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      15       50      335 DOROTHEA/dexter_public.info\n",
      "       8       36      268 DOROTHEA/dorothea.param\n",
      "      16       50      335 DOROTHEA/dorothea_public.info\n",
      "     800   730851  4304832 DOROTHEA/dorothea_test.data\n",
      "     800   727760  4287039 DOROTHEA/dorothea_train.data\n",
      "     800      800     2322 DOROTHEA/dorothea_train.solution\n",
      "     350   317752  1871651 DOROTHEA/dorothea_valid.data\n",
      "    2789  1777299 10466782 total\n"
     ]
    }
   ],
   "source": [
    "# sumery on DOROTHEA DATA\n",
    "\n",
    "data_dir = 'DOROTHEA'             \n",
    "data_name = 'dorothea'\n",
    "!wc $data_dir/* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file found : /home/tochange/Documents/L2INFO/S2/rattrapages/miniProjet/FeatureSelectionChallenge/DOROTHEA/DOROTHEA/dorothea_public.info\n",
      "-------------------- file_to_libsvm  ---------------------\n",
      "-------------------- file_to_libsvm  ---------------------\n",
      "-------------------- file_to_libsvm  ---------------------\n",
      "DataManager : dorothea\n",
      "info:\n",
      "\tusage = AutoML challenge 2014\n",
      "\tname = dorothea\n",
      "\ttask = binary.classification\n",
      "\ttarget_type = Binary\n",
      "\tfeat_type = Binary\n",
      "\tmetric = auc_metric\n",
      "\tfeat_num = 100000\n",
      "\ttarget_num = 1\n",
      "\tlabel_num = 2\n",
      "\ttrain_num = 800\n",
      "\tvalid_num = 350\n",
      "\ttest_num = 800\n",
      "\thas_categorical = 0\n",
      "\thas_missing = 0\n",
      "\tis_sparse = 1\n",
      "\ttime_budget = 100\n",
      "\tformat = sparse_binary\n",
      "data:\n",
      "\tX_train = array(800, 100000)\n",
      "\tY_train = array(800,)\n",
      "\tX_valid = array(350, 100000)\n",
      "\tY_valid = array(0,)\n",
      "\tX_test = array(800, 100000)\n",
      "\tY_test = array(0,)\n",
      "feat_type:\tarray(100000,)\n",
      "feat_idx:\tarray(0,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from data_manager import DataManager\n",
    "D = DataManager('dorothea', data_dir);\n",
    "print(D)\n",
    "Xtr = D.data['X_train']\n",
    "\n",
    "Ytr = D.data['Y_train']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 190)\t1.0\n",
      "  (0, 366)\t1.0\n",
      "  (0, 613)\t1.0\n",
      "  (0, 633)\t1.0\n",
      "  (0, 710)\t1.0\n",
      "  (0, 1201)\t1.0\n",
      "  (0, 1219)\t1.0\n",
      "  (0, 1310)\t1.0\n",
      "  (0, 1471)\t1.0\n",
      "  (0, 1729)\t1.0\n",
      "  (0, 2280)\t1.0\n",
      "  (0, 2571)\t1.0\n",
      "  (0, 2601)\t1.0\n",
      "  (0, 2610)\t1.0\n",
      "  (0, 2823)\t1.0\n",
      "  (0, 2854)\t1.0\n",
      "  (0, 2939)\t1.0\n",
      "  (0, 3148)\t1.0\n",
      "  (0, 3312)\t1.0\n",
      "  (0, 3559)\t1.0\n",
      "  (0, 3567)\t1.0\n",
      "  (0, 3823)\t1.0\n",
      "  (0, 4184)\t1.0\n",
      "  (0, 4265)\t1.0\n",
      "  (0, 4365)\t1.0\n",
      "  :\t:\n",
      "  (799, 97875)\t1.0\n",
      "  (799, 97898)\t1.0\n",
      "  (799, 98031)\t1.0\n",
      "  (799, 98265)\t1.0\n",
      "  (799, 98276)\t1.0\n",
      "  (799, 98300)\t1.0\n",
      "  (799, 98341)\t1.0\n",
      "  (799, 98352)\t1.0\n",
      "  (799, 98412)\t1.0\n",
      "  (799, 98418)\t1.0\n",
      "  (799, 98447)\t1.0\n",
      "  (799, 98457)\t1.0\n",
      "  (799, 98467)\t1.0\n",
      "  (799, 98634)\t1.0\n",
      "  (799, 98891)\t1.0\n",
      "  (799, 99117)\t1.0\n",
      "  (799, 99336)\t1.0\n",
      "  (799, 99620)\t1.0\n",
      "  (799, 99624)\t1.0\n",
      "  (799, 99738)\t1.0\n",
      "  (799, 99744)\t1.0\n",
      "  (799, 99754)\t1.0\n",
      "  (799, 99827)\t1.0\n",
      "  (799, 99954)\t1.0\n",
      "  (799, 99966)\t1.0\n"
     ]
    }
   ],
   "source": [
    "Xtr = D.data['X_train']\n",
    "print(Xtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,\n",
       "       -1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,  1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1., -1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1.,  1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "        1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "       -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1.,  1., -1., -1., -1., -1., -1., -1.,  1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1.,  1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytr = D.data['Y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainData.loc[:10,:10].plot() #selection of some column to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arcene_valid.data importation as a dataframe\n",
    "#removal of NaN values\n",
    "validData = Xtr\n",
    "\n",
    "\n",
    "#validData  # the standard output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arcene_train.labels importation as a dataframe\n",
    "#removal of NaN values\n",
    "\n",
    "\n",
    "trainLabels = Ytr\n",
    "#trainLabels # the standard output dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 873 fields in line 3, saw 1169\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-301b3c6bd2bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#arcene_valid.data importation as a dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#removal of NaN values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvalidData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_valid.data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mvalidData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"any\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 873 fields in line 3, saw 1169\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arcene_valid.data importation as a dataframe\n",
    "#removal of NaN values\n",
    "validLabels = pd.read_csv(data_name+\"_valid.labels\", sep=\" \", header=None)  # The data are loaded as a Pandas Data Frame\n",
    "validLabels=validLabels.dropna(axis=1,how=\"any\")\n",
    "#validLabels  # the standard output dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naives Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tochange/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:542: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '58 228 303 518 669 717 735 852 868 982 1035 1069 1131 1188 1268 1331 1384 1395 1418 1419 1467 1475 1498 1533 1608 1785 1882 1888 1894 1938 2032 2057 2066 2094 2131 2140 2294 2301 2304 2307 2315 2385 2399 2426 2466 2471 2575 2584 2636 2646 2673 2689 2691 2827 2845 2854 2861 3101 3176 3221 3237 3399 3426 3463 3510 3648 3687 3705 3711 3822 3824 3840 3884 3927 3966 3992 4068 4084 4185 4186 4204 4333 4537 4605 4656 4730 4875 4888 4910 4978 5138 5147 5169 5203 5287 5289 5346 5456 5495 5591 5594 5600 5612 5639 5660 5696 5698 5777 5809 5813 5870 5877 5889 5960 5968 5971 5976 6020 6037 6064 6107 6136 6140 6300 6406 6426 6468 6512 6528 6542 6663 6701 6771 6815 6828 6833 6876 6883 6963 6975 7051 7090 7124 7243 7255 7306 7311 7425 7462 7640 7648 7652 7714 7765 7801 7860 7874 7965 8033 8109 8146 8197 8233 8243 8246 8280 8475 8628 8629 8655 8676 8703 8761 8794 8821 8856 8983 9017 9319 9336 9346 9389 9517 9557 9567 9677 9680 9842 9860 10008 10099 10167 10180 10205 10353 10395 10415 10490 10591 10636 10690 10749 10757 10766 10793 10839 10868 10885 10962 10975 10988 11010 11179 11204 11221 11229 11252 11325 11335 11508 11596 11678 11747 11751 11771 11780 11858 12071 12304 12315 12367 12380 12435 12439 12536 12582 12656 12693 12711 12768 12802 12877 13034 13049 13052 13055 13078 13097 13099 13216 13239 13303 13311 13377 13471 13503 13567 13584 13602 13621 13655 13782 13817 13839 13945 13946 14003 14068 14084 14086 14095 14134 14217 14246 14266 14327 14336 14532 14611 14630 14666 14776 14865 14873 14899 14964 14992 15027 15028 15051 15080 15276 15321 15384 15418 15495 15509 15574 15579 15594 15611 15747 15762 15879 15901 15973 15980 16059 16111 16141 16209 16236 16237 16257 16274 16320 16324 16410 16530 16542 16632 16652 16838 16846 16875 16975 17033 17061 17112 17119 17173 17246 17247 17543 17594 17596 17646 17661 17677 17711 17762 17802 17808 17906 18025 18035 18288 18543 18678 18716 18724 18914 18924 18996 19168 19381 19395 19434 19471 19480 19572 19640 19660 19690 19694 19716 19793 19853 19875 19921 19979 20023 20089 20172 20259 20280 20326 20354 20438 20623 20640 20767 20897 20898 20929 20932 20952 21021 21077 21118 21160 21259 21268 21326 21480 21621 21671 21701 21807 21867 21889 21904 21926 21981 21988 21996 22015 22016 22136 22146 22197 22208 22223 22314 22327 22409 22424 22468 22506 22570 22623 22635 22712 22761 22785 22792 22819 22868 22907 22911 22991 23017 23033 23076 23137 23160 23232 23330 23369 23413 23465 23471 23568 23590 23736 23797 23857 23991 24002 24120 24185 24251 24476 24555 24567 24571 24647 24705 24718 24772 24774 24831 24842 24855 24867 25029 25031 25042 25083 25143 25153 25225 25228 25261 25288 25383 25505 25514 25527 25562 25670 25741 25749 25823 25850 25863 25942 25970 25987 26026 26153 26200 26211 26245 26277 26309 26332 26342 26358 26401 26425 26479 26575 26615 26665 26709 26745 26790 26813 26817 26899 27051 27295 27343 27391 27400 27472 27568 27680 27868 27881 27942 28009 28101 28153 28235 28280 28392 28420 28432 28461 28465 28484 28542 28607 28628 28633 28634 28737 28801 28830 28884 28964 28968 28978 29014 29059 29146 29173 29206 29253 29274 29299 29334 29407 29483 29498 29537 29564 29588 29812 29866 29891 29967 29980 30027 30144 30170 30185 30287 30418 30564 30602 30635 30688 30802 30846 30926 30965 31089 31192 31222 31299 31365 31377 31401 31671 31726 31855 31888 31981 31985 32039 32053 32104 32134 32303 32357 32370 32447 32480 32528 32584 32721 32746 32747 32846 33081 33087 33092 33143 33156 33292 33305 33382 33414 33424 33449 33490 33591 33601 33610 33634 33647 33686 33714 33727 33795 33809 33867 33891 33915 33989 34003 34034 34081 34107 34200 34231 34242 34294 34310 34330 34398 34422 34456 34529 34572 34647 34709 34771 34792 34798 34838 34862 34894 34965 35008 35018 35036 35037 35212 35287 35304 35347 35437 35465 35470 35510 35525 35538 35552 35579 35603 35632 35710 35716 35765 35766 35805 35899 35929 36005 36020 36247 36250 36264 36273 36281 36352 36368 36407 36472 36501 36599 36607 36610 36624 36715 36737 36835 36872 36904 36910 36923 36952 36975 37094 37096 37175 37299 37307 37376 37390 37402 37409 37419 37440 37487 37503 37547 37572 37608 37710 37817 37834 37839 37906 37955 38196 38273 38280 38324 38333 38413 38442 38465 38494 38549 38553 38632 38785 38866 39047 39237 39345 39432 39519 39538 39550 39590 39595 39611 39623 39634 39697 39732 39800 39823 39841 39854 39867 39933 40053 40110 40237 40272 40298 40434 40442 40473 40476 40550 40622 40696 40706 40710 40815 40865 40963 41031 41041 41107 41120 41151 41203 41244 41284 41363 41382 41409 41413 41434 41439 41511 41533 41590 41594 41608 41642 41725 41739 41773 41796 42050 42107 42156 42388 42423 42450 42464 42504 42565 42575 42632 42673 42683 42761 42782 42811 42820 42964 42980 42992 43136 43209 43215 43295 43312 43386 43424 43457 43490 43554 43571 43631 43657 43932 43935 43953 43970 44009 44039 44082 44248 44361 44432 44461 44535 44571 44584 44602 44615 44643 44644 44737 44739 44802 44864 44872 44881 44931 45036 45037 45042 45066 45087 45209 45343 45364 45374 45392 45458 45497 45518 45605 45614 45672 45762 45771 45773 45781 45859 45880 45928 45941 45968 45975 46017 46043 46066 46069 46243 46299 46331 46406 46486 46597 46621 46690 46695 46910 47018 47027 47033 47184 47222 47228 47403 47406 47425 47444 47505 47663 47700 47774 47777 47882 47942 48051 48075 48135 48177 48214 48218 48307 48321 48327 48424 48425 48565 48566 48573 48581 48675 48709 48758 48941 48957 48992 49022 49109 49112 49212 49215 49254 49387 49412 49513 49664 49721 49722 49733 49756 49880 49957 49973 50028 50114 50138 50250 50259 50331 50460 50464 50521 50535 50543 50606 50625 50649 50665 50672 50827 50912 50930 50951 50999 51009 51057 51213 51250 51424 51491 51532 51674 51738 51988 52022 52043 52086 52102 52139 52282 52361 52373 52442 52541 52571 52719 52827 52862 52955 52976 52993 53076 53138 53188 53223 53264 53278 53335 53388 53484 53517 53519 53623 53651 53662 53677 53685 53729 53742 53776 53850 53855 53897 54092 54131 54196 54303 54344 54360 54427 54463 54473 54507 54608 54700 54809 54835 54874 54924 55098 55107 55217 55229 55299 55321 55322 55349 55430 55479 55498 55549 55552 55584 55619 55629 55764 55796 55956 55987 56061 56202 56243 56262 56276 56357 56390 56420 56435 56466 56521 56555 56591 56627 56630 56698 56699 56766 56801 57017 57066 57106 57161 57267 57279 57285 57403 57430 57456 57478 57518 57523 57589 57625 57646 57665 57688 57766 57790 57938 57994 58184 58186 58188 58254 58334 58419 58463 58495 58514 58525 58594 58603 58619 58718 58775 58790 58809 58830 58910 58961 59001 59015 59021 59035 59171 59211 59259 59260 59271 59433 59445 59525 59534 59545 59571 59595 59643 59744 59751 59775 59799 59892 59893 59910 59917 59945 60008 60062 60065 60189 60279 60365 60418 60431 60442 60538 60653 60657 60666 60694 60704 60773 60850 60933 60980 61049 61074 61091 61145 61146 61182 61222 61278 61298 61342 61372 61402 61409 61572 61622 61822 61885 61886 61910 61911 61913 61929 61950 61963 62003 62017 62100 62108 62117 62140 62291 62336 62371 62480 62496 62516 62536 62544 62593 62626 62651 62683 62745 62825 62856 62879 62940 62980 63141 63189 63211 63294 63316 63334 63340 63353 63365 63513 63528 63625 63635 63720 63837 63839 63877 63962 64009 64100 64183 64262 64285 64333 64416 64424 64429 64446 64453 64609 64721 64757 64874 64917 64951 64995 65014 65064 65095 65120 65254 65307 65309 65321 65324 65334 65388 65472 65591 65711 65781 65822 65899 66053 66078 66123 66256 66318 66324 66495 66565 66610 66628 66639 66701 66807 66825 66893 66904 66975 67030 67129 67204 67259 67317 67346 67356 67395 67397 67407 67408 67431 67467 67473 67554 67557 67575 67636 67819 67855 67912 67958 67960 68123 68149 68194 68344 68346 68349 68365 68462 68555 68654 68658 68837 68854 68895 68903 68914 68991 69002 69034 69111 69112 69148 69294 69327 69338 69348 69382 69462 69553 69581 69593 69612 69643 69858 69862 69869 69877 69951 70041 70073 70103 70135 70147 70154 70172 70206 70236 70333 70338 70343 70634 70740 70760 70820 70826 70842 70856 70867 70897 70914 70935 70973 71093 71139 71185 71210 71220 71370 71378 71443 71466 71526 71559 71583 71591 71820 71856 71904 71906 71937 71942 71962 72003 72123 72128 72147 72148 72174 72187 72236 72452 72673 72782 72836 73020 73045 73074 73080 73151 73159 73242 73306 73488 73509 73513 73563 73806 73859 73883 73886 73930 74093 74184 74317 74332 74454 74460 74628 74634 74674 74880 74973 75164 75301 75311 75384 75393 75419 75487 75520 75528 75703 75723 75746 75801 75885 75894 75926 76078 76162 76417 76458 76475 76495 76510 76544 76558 76573 76696 76772 76891 76933 76947 77006 77053 77201 77255 77285 77376 77419 77637 77691 77828 77891 77934 77997 78066 78097 78122 78124 78190 78199 78356 78361 78385 78407 78516 78840 78866 79105 79160 79166 79174 79185 79349 79362 79398 79517 79570 79591 79599 79601 79666 79736 79811 79819 79823 79825 79863 80002 80004 80109 80181 80191 80220 80311 80352 80441 80485 80492 80512 80562 80600 80627 80759 80839 80933 81004 81066 81087 81145 81276 81281 81298 81338 81367 81383 81435 81494 81521 81537 81538 81578 81611 81784 81813 81823 81849 81854 81896 81921 81930 81940 81973 82135 82170 82197 82202 82346 82446 82544 82608 82622 82626 82735 82786 82878 82883 82911 83058 83112 83158 83198 83332 83401 83406 83574 83575 83609 83622 83654 83673 83719 83805 83900 83931 84011 84037 84073 84211 84256 84266 84287 84297 84417 84424 84436 84449 84633 84697 84812 84845 84921 84970 84980 84995 85037 85166 85206 85212 85291 85292 85335 85390 85420 85459 85468 85557 85584 85645 85732 85782 85849 85972 86032 86074 86119 86229 86233 86243 86273 86330 86391 86607 86608 86698 86711 86820 87051 87069 87101 87170 87288 87354 87454 87460 87532 87545 87553 87617 87653 87660 87678 87779 87798 87818 87877 87891 88057 88078 88102 88133 88176 88188 88340 88342 88388 88397 88402 88423 88553 88584 88651 88703 88745 88753 88780 88848 88852 88916 88918 88934 88947 89001 89030 89100 89111 89192 89202 89240 89253 89271 89272 89291 89314 89336 89379 89416 89484 89513 89599 89631 89663 89797 89892 89903 89953 90084 90127 90138 90165 90171 90268 90378 90431 90436 90459 90475 90622 90845 90859 90972 90995 91107 91145 91156 91188 91192 91194 91195 91202 91329 91535 91545 91574 91589 91592 91674 91692 91724 91790 91907 91911 91920 92087 92101 92110 92124 92153 92238 92243 92404 92405 92458 92504 92639 92780 92901 92950 92974 92987 92991 93061 93068 93096 93134 93138 93201 93309 93355 93470 93502 93513 93577 93630 93633 93639 93706 93724 93739 93827 93832 93843 93845 93897 93957 94139 94147 94159 94161 94211 94225 94325 94334 94335 94337 94382 94401 94504 94579 94589 94684 94697 94777 94838 94889 94892 94991 95097 95299 95348 95404 95418 95511 95533 95618 95655 95811 95858 95876 95973 95981 96063 96161 96198 96345 96460 96461 96525 96555 96645 96666 96720 96766 96771 97099 97127 97146 97154 97155 97191 97292 97403 97443 97500 97678 97732 97745 97751 97797 97859 97884 98153 98172 98222 98261 98272 98285 98318 98325 98464 98513 98536 98550 98589 98705 98779 98862 98963 99020 99111 99146 99190 99258 99259 99318 99347 99359 99439 99495 99562 99572 99645 99710 99759 99961 99991'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-95e7e4ac0d13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m    192\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '58 228 303 518 669 717 735 852 868 982 1035 1069 1131 1188 1268 1331 1384 1395 1418 1419 1467 1475 1498 1533 1608 1785 1882 1888 1894 1938 2032 2057 2066 2094 2131 2140 2294 2301 2304 2307 2315 2385 2399 2426 2466 2471 2575 2584 2636 2646 2673 2689 2691 2827 2845 2854 2861 3101 3176 3221 3237 3399 3426 3463 3510 3648 3687 3705 3711 3822 3824 3840 3884 3927 3966 3992 4068 4084 4185 4186 4204 4333 4537 4605 4656 4730 4875 4888 4910 4978 5138 5147 5169 5203 5287 5289 5346 5456 5495 5591 5594 5600 5612 5639 5660 5696 5698 5777 5809 5813 5870 5877 5889 5960 5968 5971 5976 6020 6037 6064 6107 6136 6140 6300 6406 6426 6468 6512 6528 6542 6663 6701 6771 6815 6828 6833 6876 6883 6963 6975 7051 7090 7124 7243 7255 7306 7311 7425 7462 7640 7648 7652 7714 7765 7801 7860 7874 7965 8033 8109 8146 8197 8233 8243 8246 8280 8475 8628 8629 8655 8676 8703 8761 8794 8821 8856 8983 9017 9319 9336 9346 9389 9517 9557 9567 9677 9680 9842 9860 10008 10099 10167 10180 10205 10353 10395 10415 10490 10591 10636 10690 10749 10757 10766 10793 10839 10868 10885 10962 10975 10988 11010 11179 11204 11221 11229 11252 11325 11335 11508 11596 11678 11747 11751 11771 11780 11858 12071 12304 12315 12367 12380 12435 12439 12536 12582 12656 12693 12711 12768 12802 12877 13034 13049 13052 13055 13078 13097 13099 13216 13239 13303 13311 13377 13471 13503 13567 13584 13602 13621 13655 13782 13817 13839 13945 13946 14003 14068 14084 14086 14095 14134 14217 14246 14266 14327 14336 14532 14611 14630 14666 14776 14865 14873 14899 14964 14992 15027 15028 15051 15080 15276 15321 15384 15418 15495 15509 15574 15579 15594 15611 15747 15762 15879 15901 15973 15980 16059 16111 16141 16209 16236 16237 16257 16274 16320 16324 16410 16530 16542 16632 16652 16838 16846 16875 16975 17033 17061 17112 17119 17173 17246 17247 17543 17594 17596 17646 17661 17677 17711 17762 17802 17808 17906 18025 18035 18288 18543 18678 18716 18724 18914 18924 18996 19168 19381 19395 19434 19471 19480 19572 19640 19660 19690 19694 19716 19793 19853 19875 19921 19979 20023 20089 20172 20259 20280 20326 20354 20438 20623 20640 20767 20897 20898 20929 20932 20952 21021 21077 21118 21160 21259 21268 21326 21480 21621 21671 21701 21807 21867 21889 21904 21926 21981 21988 21996 22015 22016 22136 22146 22197 22208 22223 22314 22327 22409 22424 22468 22506 22570 22623 22635 22712 22761 22785 22792 22819 22868 22907 22911 22991 23017 23033 23076 23137 23160 23232 23330 23369 23413 23465 23471 23568 23590 23736 23797 23857 23991 24002 24120 24185 24251 24476 24555 24567 24571 24647 24705 24718 24772 24774 24831 24842 24855 24867 25029 25031 25042 25083 25143 25153 25225 25228 25261 25288 25383 25505 25514 25527 25562 25670 25741 25749 25823 25850 25863 25942 25970 25987 26026 26153 26200 26211 26245 26277 26309 26332 26342 26358 26401 26425 26479 26575 26615 26665 26709 26745 26790 26813 26817 26899 27051 27295 27343 27391 27400 27472 27568 27680 27868 27881 27942 28009 28101 28153 28235 28280 28392 28420 28432 28461 28465 28484 28542 28607 28628 28633 28634 28737 28801 28830 28884 28964 28968 28978 29014 29059 29146 29173 29206 29253 29274 29299 29334 29407 29483 29498 29537 29564 29588 29812 29866 29891 29967 29980 30027 30144 30170 30185 30287 30418 30564 30602 30635 30688 30802 30846 30926 30965 31089 31192 31222 31299 31365 31377 31401 31671 31726 31855 31888 31981 31985 32039 32053 32104 32134 32303 32357 32370 32447 32480 32528 32584 32721 32746 32747 32846 33081 33087 33092 33143 33156 33292 33305 33382 33414 33424 33449 33490 33591 33601 33610 33634 33647 33686 33714 33727 33795 33809 33867 33891 33915 33989 34003 34034 34081 34107 34200 34231 34242 34294 34310 34330 34398 34422 34456 34529 34572 34647 34709 34771 34792 34798 34838 34862 34894 34965 35008 35018 35036 35037 35212 35287 35304 35347 35437 35465 35470 35510 35525 35538 35552 35579 35603 35632 35710 35716 35765 35766 35805 35899 35929 36005 36020 36247 36250 36264 36273 36281 36352 36368 36407 36472 36501 36599 36607 36610 36624 36715 36737 36835 36872 36904 36910 36923 36952 36975 37094 37096 37175 37299 37307 37376 37390 37402 37409 37419 37440 37487 37503 37547 37572 37608 37710 37817 37834 37839 37906 37955 38196 38273 38280 38324 38333 38413 38442 38465 38494 38549 38553 38632 38785 38866 39047 39237 39345 39432 39519 39538 39550 39590 39595 39611 39623 39634 39697 39732 39800 39823 39841 39854 39867 39933 40053 40110 40237 40272 40298 40434 40442 40473 40476 40550 40622 40696 40706 40710 40815 40865 40963 41031 41041 41107 41120 41151 41203 41244 41284 41363 41382 41409 41413 41434 41439 41511 41533 41590 41594 41608 41642 41725 41739 41773 41796 42050 42107 42156 42388 42423 42450 42464 42504 42565 42575 42632 42673 42683 42761 42782 42811 42820 42964 42980 42992 43136 43209 43215 43295 43312 43386 43424 43457 43490 43554 43571 43631 43657 43932 43935 43953 43970 44009 44039 44082 44248 44361 44432 44461 44535 44571 44584 44602 44615 44643 44644 44737 44739 44802 44864 44872 44881 44931 45036 45037 45042 45066 45087 45209 45343 45364 45374 45392 45458 45497 45518 45605 45614 45672 45762 45771 45773 45781 45859 45880 45928 45941 45968 45975 46017 46043 46066 46069 46243 46299 46331 46406 46486 46597 46621 46690 46695 46910 47018 47027 47033 47184 47222 47228 47403 47406 47425 47444 47505 47663 47700 47774 47777 47882 47942 48051 48075 48135 48177 48214 48218 48307 48321 48327 48424 48425 48565 48566 48573 48581 48675 48709 48758 48941 48957 48992 49022 49109 49112 49212 49215 49254 49387 49412 49513 49664 49721 49722 49733 49756 49880 49957 49973 50028 50114 50138 50250 50259 50331 50460 50464 50521 50535 50543 50606 50625 50649 50665 50672 50827 50912 50930 50951 50999 51009 51057 51213 51250 51424 51491 51532 51674 51738 51988 52022 52043 52086 52102 52139 52282 52361 52373 52442 52541 52571 52719 52827 52862 52955 52976 52993 53076 53138 53188 53223 53264 53278 53335 53388 53484 53517 53519 53623 53651 53662 53677 53685 53729 53742 53776 53850 53855 53897 54092 54131 54196 54303 54344 54360 54427 54463 54473 54507 54608 54700 54809 54835 54874 54924 55098 55107 55217 55229 55299 55321 55322 55349 55430 55479 55498 55549 55552 55584 55619 55629 55764 55796 55956 55987 56061 56202 56243 56262 56276 56357 56390 56420 56435 56466 56521 56555 56591 56627 56630 56698 56699 56766 56801 57017 57066 57106 57161 57267 57279 57285 57403 57430 57456 57478 57518 57523 57589 57625 57646 57665 57688 57766 57790 57938 57994 58184 58186 58188 58254 58334 58419 58463 58495 58514 58525 58594 58603 58619 58718 58775 58790 58809 58830 58910 58961 59001 59015 59021 59035 59171 59211 59259 59260 59271 59433 59445 59525 59534 59545 59571 59595 59643 59744 59751 59775 59799 59892 59893 59910 59917 59945 60008 60062 60065 60189 60279 60365 60418 60431 60442 60538 60653 60657 60666 60694 60704 60773 60850 60933 60980 61049 61074 61091 61145 61146 61182 61222 61278 61298 61342 61372 61402 61409 61572 61622 61822 61885 61886 61910 61911 61913 61929 61950 61963 62003 62017 62100 62108 62117 62140 62291 62336 62371 62480 62496 62516 62536 62544 62593 62626 62651 62683 62745 62825 62856 62879 62940 62980 63141 63189 63211 63294 63316 63334 63340 63353 63365 63513 63528 63625 63635 63720 63837 63839 63877 63962 64009 64100 64183 64262 64285 64333 64416 64424 64429 64446 64453 64609 64721 64757 64874 64917 64951 64995 65014 65064 65095 65120 65254 65307 65309 65321 65324 65334 65388 65472 65591 65711 65781 65822 65899 66053 66078 66123 66256 66318 66324 66495 66565 66610 66628 66639 66701 66807 66825 66893 66904 66975 67030 67129 67204 67259 67317 67346 67356 67395 67397 67407 67408 67431 67467 67473 67554 67557 67575 67636 67819 67855 67912 67958 67960 68123 68149 68194 68344 68346 68349 68365 68462 68555 68654 68658 68837 68854 68895 68903 68914 68991 69002 69034 69111 69112 69148 69294 69327 69338 69348 69382 69462 69553 69581 69593 69612 69643 69858 69862 69869 69877 69951 70041 70073 70103 70135 70147 70154 70172 70206 70236 70333 70338 70343 70634 70740 70760 70820 70826 70842 70856 70867 70897 70914 70935 70973 71093 71139 71185 71210 71220 71370 71378 71443 71466 71526 71559 71583 71591 71820 71856 71904 71906 71937 71942 71962 72003 72123 72128 72147 72148 72174 72187 72236 72452 72673 72782 72836 73020 73045 73074 73080 73151 73159 73242 73306 73488 73509 73513 73563 73806 73859 73883 73886 73930 74093 74184 74317 74332 74454 74460 74628 74634 74674 74880 74973 75164 75301 75311 75384 75393 75419 75487 75520 75528 75703 75723 75746 75801 75885 75894 75926 76078 76162 76417 76458 76475 76495 76510 76544 76558 76573 76696 76772 76891 76933 76947 77006 77053 77201 77255 77285 77376 77419 77637 77691 77828 77891 77934 77997 78066 78097 78122 78124 78190 78199 78356 78361 78385 78407 78516 78840 78866 79105 79160 79166 79174 79185 79349 79362 79398 79517 79570 79591 79599 79601 79666 79736 79811 79819 79823 79825 79863 80002 80004 80109 80181 80191 80220 80311 80352 80441 80485 80492 80512 80562 80600 80627 80759 80839 80933 81004 81066 81087 81145 81276 81281 81298 81338 81367 81383 81435 81494 81521 81537 81538 81578 81611 81784 81813 81823 81849 81854 81896 81921 81930 81940 81973 82135 82170 82197 82202 82346 82446 82544 82608 82622 82626 82735 82786 82878 82883 82911 83058 83112 83158 83198 83332 83401 83406 83574 83575 83609 83622 83654 83673 83719 83805 83900 83931 84011 84037 84073 84211 84256 84266 84287 84297 84417 84424 84436 84449 84633 84697 84812 84845 84921 84970 84980 84995 85037 85166 85206 85212 85291 85292 85335 85390 85420 85459 85468 85557 85584 85645 85732 85782 85849 85972 86032 86074 86119 86229 86233 86243 86273 86330 86391 86607 86608 86698 86711 86820 87051 87069 87101 87170 87288 87354 87454 87460 87532 87545 87553 87617 87653 87660 87678 87779 87798 87818 87877 87891 88057 88078 88102 88133 88176 88188 88340 88342 88388 88397 88402 88423 88553 88584 88651 88703 88745 88753 88780 88848 88852 88916 88918 88934 88947 89001 89030 89100 89111 89192 89202 89240 89253 89271 89272 89291 89314 89336 89379 89416 89484 89513 89599 89631 89663 89797 89892 89903 89953 90084 90127 90138 90165 90171 90268 90378 90431 90436 90459 90475 90622 90845 90859 90972 90995 91107 91145 91156 91188 91192 91194 91195 91202 91329 91535 91545 91574 91589 91592 91674 91692 91724 91790 91907 91911 91920 92087 92101 92110 92124 92153 92238 92243 92404 92405 92458 92504 92639 92780 92901 92950 92974 92987 92991 93061 93068 93096 93134 93138 93201 93309 93355 93470 93502 93513 93577 93630 93633 93639 93706 93724 93739 93827 93832 93843 93845 93897 93957 94139 94147 94159 94161 94211 94225 94325 94334 94335 94337 94382 94401 94504 94579 94589 94684 94697 94777 94838 94889 94892 94991 95097 95299 95348 95404 95418 95511 95533 95618 95655 95811 95858 95876 95973 95981 96063 96161 96198 96345 96460 96461 96525 96555 96645 96666 96720 96766 96771 97099 97127 97146 97154 97155 97191 97292 97403 97443 97500 97678 97732 97745 97751 97797 97859 97884 98153 98172 98222 98261 98272 98285 98318 98325 98464 98513 98536 98550 98589 98705 98779 98862 98963 99020 99111 99146 99190 99258 99259 99318 99347 99359 99439 99495 99562 99572 99645 99710 99759 99961 99991'"
     ]
    }
   ],
   "source": [
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#clf = GaussianNB()\n",
    "#clf.fit(trainData, trainLabels)\n",
    "#labelsPred = clf.predict(validData);\n",
    "#acc = accuracy_score(validLabels,labelsPred)\n",
    "#acc\n",
    "\n",
    "#10-fols cross-validation with DecisionTree\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = clf = GaussianNB()\n",
    "print (cross_val_score(clf,trainData,trainLabels,cv=10, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-65efa67d5a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainData' is not defined"
     ]
    }
   ],
   "source": [
    "#from sklearn import tree\n",
    "#from sklearn.metrics import accuracy_score\n",
    "\n",
    "#clf = tree.DecisionTreeClassifier()\n",
    "#clf.fit(trainData, trainLabels)\n",
    "#labelsPred = clf.predict(validData);\n",
    "#acc = accuracy_score(validLabels,labelsPred)\n",
    "#acc\n",
    "\n",
    "#10-fols cross-validation with DecisionTree\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "print (cross_val_score(clf,trainData,trainLabels,cv=10, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c4d5a22ff5b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'brute'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainData' is not defined"
     ]
    }
   ],
   "source": [
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#clf = KNeighborsClassifier(n_neighbors=1,algorithm='brute')\n",
    "#clf.fit(trainData, trainLabels)\n",
    "#labelsPred = clf.predict(validData);\n",
    "#acc = accuracy_score(validLabels,labelsPred)\n",
    "#acc\n",
    "\n",
    "\n",
    "#10-fols cross-validation with DecisionTree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = KNeighborsClassifier(n_neighbors=1,algorithm='brute')\n",
    "print (cross_val_score(clf,trainData,trainLabels,cv=10, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-496eeadd67f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainLabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainData' is not defined"
     ]
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "#clf.fit(trainData, trainLabels)\n",
    "#labelsPred = clf.predict(validData);\n",
    "#acc = accuracy_score(validLabels,labelsPred)\n",
    "#acc\n",
    "\n",
    "\n",
    "#10-fols cross-validation with DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "print (cross_val_score(clf,trainData,trainLabels,cv=10, scoring=\"accuracy\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
